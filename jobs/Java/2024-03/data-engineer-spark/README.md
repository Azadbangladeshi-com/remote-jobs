# [Data Engineer - Spark](https://www.remotewlb.com/apply/data-engineer-spark)  
### ALTEN  
#### `🌎 Morocco`  

### Description de l'entreprise

ALTEN MAROC filiale du leader mondial de l'Ingénierie et du Conseil en Technologies (ICT), avec 40 000 collaborateurs au monde dont plus de +2200 au Maroc répartis sur trois Centres d'Excellence à Fès, Rabat et Casa, nous accompagnons nos clients en offrant des solutions d'ingénierie agiles et novatrices pour les grands donneurs d'ordre mondial dans les secteurs de l'automobile, l'aéronautique, les réseaux & télécoms, Software & Outils.

### Rejoindre ALTEN MAROC c'est bénéficier :

  * Des parcours professionnels diversifiés avec des opportunités de carrière, une mobilité interne, sectorielle, géographique et métiers.
  * Des formations certifiantes et diplômantes.
  * Des événements réguliers pour combiner bien être et performance.

### Description du poste

Au sein de la direction « Plateforme Data », le consultant intégrera une équipe SCRUM et se

concentrera sur un périmètre fonctionnel spécifique. Son rôle consistera à contribuer à des projets

data en apportant son expertise sur les tâches suivantes :

● Participer a la realisation de l’ensemble des projets metiers (usages)

● Prendre en charge les demandes de corrections provenant d’incidents ou d’anomalies

● Participer a l'auto-formation et a la montee en competences de l’equipe de developpement

● Appliquer les bonnes pratiques et les normes de developpement

● Mettre en pratique les methodes ≪ devops ≫

● Contribuer aux chiffrages des usages et a la constitution des releases

● Contribuer a l’automatisation du delivery

### ● Developper et documenter son code

● Travailler au sein d’une equipe SCRUM (PO, developpeurs, QA, Support)

### Qualifications

### Compétences techniques obligatoires :

● Experience en architecture de systemes distribues Big Data

● Scala/Java (experience obligatoire dans l’un des deux langages)

● Ecosysteme Big Data (Hadoop, Spark, Apache Kafka, Avro ...)

● Maitrise de la CI/CD et des outils de deploiement et orchestration (Jenkins, GitLab, Kubernetes,

### Docker, Ansible …)

### ● Concepts fondamentaux de Kafka

● Bases de donnees NoSQL (Cassandra, BigTable…)

● Moteur de recherche (Elastic Search...)

### Compétences appréciées :

### ● Kafka-Stream

● Google Cloud Platform (GCS, BigQuery, GKE, Cloud Pub/Sub, Dataproc, …)

### ● Software Craftsmanship.

### ● Veille technologique

● Participation à des meetings, des meetups, à la communauté Big Data

### Compétences personnelles :

● Très bonne communication écrite et orale (livrables et reportings de qualité)

● Esprit d'analyse et d'amélioration continue

● Curiosite, autonomie et capacité à travailler plusieurs projets en parallèle

### Informations supplémentaires

  
## CLICK TO [APPLY](https://www.remotewlb.com/apply/data-engineer-spark)

